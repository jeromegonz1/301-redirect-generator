# SCRAPING_STRATEGY.md

## ğŸ¯ Objectif

Proposer une option par dÃ©faut permettant de **scraper automatiquement** les URLs internes de deux sites (ancien et nouveau), sans intervention technique.

## âœ… Ce que fait le scraping

- Explore tous les liens internes `<a href="...">`
- Nettoie et normalise les URLs
- Ne suit pas les liens externes ou assets
- Ignore les doublons
- Limite le crawl Ã  un maximum de 200 pages par site
- Utilise un `User-Agent` dÃ©diÃ© : `301-Redirect-Bot`

## ğŸ” AccÃ¨s prÃ©prod / privÃ©

- Le scraping doit pouvoir fonctionner mÃªme sur des prÃ©productions privÃ©es
- Solutions acceptÃ©es :
  - Header `User-Agent: 301-Redirect-Bot`
  - Authentification Basic HTTP
  - Token ou clÃ© d'accÃ¨s
  - Tunnel (ngrok, Cloudflare Tunnel)

## ğŸ§  RÃ©sumÃ©

- Le scraping est le mode par dÃ©faut
- L'utilisateur peut le dÃ©sactiver si besoin
- Le systÃ¨me doit automatiquement dÃ©tecter et rÃ©cupÃ©rer les URLs internes
- Si le site est inaccessible, fallback vers input manuel